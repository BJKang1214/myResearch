<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>BJ Kang Research Story</title>
    <style>
        body {
            font-family: Arial, sans-serif;
            margin: 0;
            padding: 0;
            line-height: 1.6;
        }
        header {
            width: 100vw;
            height: 15vh;
            background: #000;
            color: #fff;
            padding: 0;
            text-align: center;
        }
        nav {
            width: 100vw;
            height: 2.5vh;
            font-family: Arial;
            background: #f4f4f4;
            padding: 1rem;
            text-align: center;
            font-size: min(2.2vw, 2.2vh);
        }
        nav a {
            margin: 0 2rem;
            text-decoration: none;
            color: #555;
        }
        section {
            padding: 3vh;
            border-bottom: 1px solid #ddd;
        }
        footer {
            background: #333;
            color: #fff;
            text-align: center;
            padding: 0.5rem 0;
        }
        h1 {
          font-size: min(2.2vw, 3.552vh);
          color: #fff;
          margin-top: 1.5vh;
        }
        h2 {
          font-size: min(2.0vw, 3.19vh);
          color: #19346a;
        }
        h3 {
          font-size: min(1.8vw, 2.83vh);
          padding-left: 1.5vw;
          margin-top: 1vh;
        }
        span {
          font-size: min(1.7vw, 2.664vh);
        }
        p {
          font-size: min(1.7vw, 2.664vh);
          padding-left: 1vw;
        }
        ul {
          font-size: min(1.7vw, 2.664vh);
          margin-left: 2vw;
        }
        li {
          font-size: min(1.7vw, 2.664vh);
          margin-left: 2vw;
        }
        .container {
            display: flex;
            <!-- border: 1px solid #ccc; -->
            padding-left: 0.2vw;
            width: 92vw;
            height: auto;
            <!-- box-shadow: 0 4px 8px rgba(0,0,0,0.1); -->
        }
        .photo {
            width: 20%;
            height: auto
            margin-top: 1.5vh;
            margin-right: 1vw;
        }
        .photo img {
            width: 100%;
            height: 100%;
            border-radius: 0.5rem;
        }
        .profile {
            width: 80%;
            height: auto
            margin-top: 1.5vh
        }
        .profile h1 {
            font-size: min(1.8vw, 2.83vh);
            color: #023c71;
            margin-left: 2vw;
            margin-top: 1vh;
        }
        .profile p {
            font-size: min(1.7vw, 2.664vh);
            line-height: 1.5;
            margin-left: 1vw;
        }
        .container_r {
            display: flex;
            <!-- border: 1px solid #ccc; -->
            padding-left: 0.2vw;
            width: 92vw;
            height: auto;
            <!-- box-shadow: 0 4px 8px rgba(0,0,0,0.1); -->
        }
        .figure {
            width: 30%;
            margin-top: 1.5vh;
            margin-right: 1vw;
        }
        .figure img {
            width: 100%;
            height: 70%;
            margin-top: 5vh;
            border-radius: 0.5rem;
        }
        .descript {
            width: 75%;
            height: auto
            margin-top: 1.5vh
        }
        .descript h1 {
            font-size: min(1.8vw, 2.83vh);
            color: #023c71;
            margin-left: 2vw;
            margin-top: 1vh;
        }
        .descript p {
            font-size: min(1.7vw, 2.664vh);
            line-height: 1.5;
            margin-left: 1vw;
        }
        .tab-container {
            width: 100%;
            max-width: 100vw;
            margin-top: 2vh;
            margin-left: 3vw;
        }
        .tab {
            padding: 0.5vw;
            cursor: grab;
            display: flex;
            justify-content: left;
            align-items: center;
            margin-top: 2vh;
            margin-bottom: 2vh;
        }
        .triangle-button {
            width: 0;
            height: 0;
            border-left: 1vh solid transparent;
            border-right: 1vh solid transparent;
            border-top: 1vh solid #333;
            cursor: pointer;
            transition: transform 0.2s;
            margin-left: 2vw;
        }
        .rotated {
            transform: rotate(180deg);
        }
        .content {
            max-height: 0;
            overflow: hidden;
            transition: max-height 0.3s ease-out;
            padding: 0 1vh;
            <!border: 1px solid #ccc;!>
            background-color: #ffffff;
        }
        .content.open {
            max-height: 100vh;
            padding: 0 10 0 10px;
        }
        .drop-zone {
            min-height: 20vh;
            border: 1px dashed #999;
            padding: 10px;
            margin-top: 10px;
        }
    </style>
</head>
<body>
    <header>
        <img src="logo_t.png" height=95% width=auto>
    </header>
    <nav>
        <a href="#home">About Me</a>
        <a href="#publications">Publications</a>
        <a href="#research">Research</a>
    </nav>
    <section id="home">
        <h2>About Me</h2>
        <h3>Byung Jun Kang</h3>
        <p><ul><li>Research Interest: </li><ul><li>Perception of Autonomous Driving(Object Detection/Tracking)</li><li>Biometrics(Face/Iris/Finger Vein Recognition)</li><li>Visual Inspection(Anomaly Detection, Active Learning, Continual Learning, Learning with Noisy Labels)</li></ul></ul></p>            
        <p><ul><li>e-mail: kangbyj@gmail.com</li><ul></p>
    </section>
    <section id="publications">
        <h2>Publications</h2>
        <h3>SCI(E) Journals</h3>
        <div class="tab-container">
            <div id="sci_tab1" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(2021~current)</span>
                <div class="triangle-button rotated" onclick="toggleContent('sci_content_current', this)"></div>
            </div>       
            <div id="sci_content_current" class="content open">
                <div class="container">
                    <div class="photo">
                        <img src="AURAdepth.jpg" alt="AURADepth">
                    </div>
                    <div class="profile">
                        <p style="color: #023c71; font-size: min(1.8vw, 2.83vh);"><b>AURA-Depth: Attention-based Uncertainty Reduction and Feature Aggregation Depth Network</b><p>
                        <p><I>Youngtak Na, Sungho Woo, Soonyoung Lee, <b>Byung Jun Kang*</b></I>
                        <br>IEEE Access, Vol. 13, pp. 58600-58611, <br>2025 <a href="https://doi.org/10.1109/ACCESS.2025.3556062">[link]</a></p>
                    </div>
                </div>
                <div class="container">
                    <div class="photo">
                        <img src="SoccerCLIP.jpg" alt="SoccerCLIP">
                    </div>
                    <div class="profile">
                        <p style="color: #023c71; font-size: min(1.8vw, 2.83vh);"><b>Soccer-CLIP : Vision Language model for Soccer Action Spotting</b><p>
                        <p><I>Yoonho Shin, Sanghoon Park, Youngsub Han, Byoung-ki Jeon, Soonyoung Lee, <b>Byung Jun Kang*</b></I>
                        <br>IEEE Access, Vol. 13, pp. 44354-44365, <br>2025 <a href="https://doi.org/10.1109/ACCESS.2025.3549293">[link]</a></p>
                    </div>
                </div>
            </div>
            <div id="sci_tab2" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(2005~2020)</span>
                <div class="triangle-button" onclick="toggleContent('sci_content_old', this)"></div>
            </div>
            <div id="sci_content_old" class="content">
                <p><I>Kwang Yong Shin, Gi Pyo Nam, Dae Sik Jeong, Dal Ho Cho, <b>Byung Jun Kang</b>, Kang Ryoung Park*, Jaihie Kim, </I> “New Iris Recognition Method for Noisy Iris Images,” Pattern Recognition Letters, vol. 33, issue. 8, pp. 991-999,  June 2012 <a href="https://doi.org/10.1016/j.patrec.2011.08.016">[link]</a></p>
                <p><I>Kwang Yong Shin, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> “Super-Resolution Iris Image Restoration Based on Multiple MLPs and CLS Filter,” Journal of Internet Technology, Vol.13, No.2, pp. 233-244, March, 2012 <a href="https://jit.ndhu.edu.tw/article/view/773">[link]</a></p>
                <p><I>Dat Tien Nguyen, Young Ho Park, Hyeon Chang Lee, Kwang Yong Shin, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Combining Touched Fingerprint and Finger-vein of a Finger, and its Usability Evaluation," Advanced Science Letters, vol. 5, No. 1, pp. 85-95, Jan. 2012 <a href="https://doi.org/10.1166/asl.2012.2177">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, Jang-Hee Yoo, Jeong Nyeo Kim, </I> “Multimodal Biometric Method that Combines Veins, Prints, and Shape of a Finger,” Optical Engineering, vol. 50, issue 1, pp. 017201, Jan. 2011 <a href="http://dx.doi.org/10.1117/1.3530023">[link]</a></p>
                <p><I>Eun Jung Han, <b>Byung Jun Kang</b>, Kang Ryoung Park*, Sangyoun Lee, </I> "Support Vector Machine-based Facial-expression Recognition Method Combining Shape and Appearance," Optical Engineering, vol. 49, issue. 11, pp. 117202, Nov. 2010 <a href="http://dx.doi.org/10.1117/1.3506200">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Multimodal Biometric Method Based on Vein and Geometry of a Single Finger," IET Computer Vision, vol. 4, issue. 3, pp. 209-217, Sep. 2010 <a href="http://dx.doi.org/10.1049/iet-cvi.2009.0081">[link]</a></p>
                <p><I>Hyun Chang Lee, <b>Byung Jun Kang</b>, Eui Chul Lee, Kang Ryoung Park*, </I> “Finger Vein Recognition by Using Weighted Local Binary Pattern Code Based on SVM,” Journal of Zhejiang University-Science C (JZUS-C), vol. 11, no. 7, pp. 514-524, July 2010 <a href="http://dx.doi.org/10.1631/jzus.C0910550">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, Jang-Hee Yoo, Kiyoung Moon, </I> "Fuzzy Difference-of-Gaussian-based Iris Recognition Method for Noisy Iris Images," Optical Engineering, vol. 49, issue. 6, pp.067001, Jun. 2010 <a href="http://dx.doi.org/10.1117/1.3447924">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A new multi-unit iris authentication based on quality assessment and score level fusion for mobile phones", Machine Vision and Applications, vol. 21, pp.541-553, Jun. 2010 <a href="http://dx.doi.org/10.1007/s00138-009-0184-0">[link]</a></p>
                <p><I>Kwang Yong Shin, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Super-Resolution Iris Image Restoration using Single Image for Iris Recognition," KSII Transactions on Internet and Information Systems, vol. 4, no. 2, pp.129-153, Apr. 2010 <a href="http://dx.doi.org/10.3837/tiis.2010.04.003">[link]</a></p>
                <p><I>Gi Pyo Nam, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Robustness of Face Recognition to Variations of Illumination on Mobile Device Based on SVM," KSII Transactions on Internet and Information Systems, vol. 4, no. 1, pp.25-44, Feb. 2010 <a href="http://dx.doi.org/10.3837/tiis.2010.01.002">[link]</a></p>
                <p><I>Young Kyoon Jang, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Novel Portable Iris Recognition System and Usability Evaluation", International Journal of Control Automation and Systems, vol. 8, pp. 91-98, Feb. 2010 <a href="http://dx.doi.org/10.1007/s12555-010-0112-0">[link]</a></p>
                <p><I>Dae Sik Jeong, Jae Won Hwang, <b>Byung Jun Kang</b>, Kang Ryoung Park*, Chee Sun Won, Dong-Kwon Park, Jaihie Kim, </I> "A New Iris Segmentation Method for Non-ideal Iris Images", Image and Vision Computing, vol. 28, issue. 2, pp.254-260, Feb. 2010 <a href="http://dx.doi.org/10.1016/j.imavis.2009.04.001">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Study on Restoration of Iris Images with Motion-and-Optical Blur on Mobile Iris Recognition Devices", International Journal of Imaging Systems and Technology, vol. 19, issue 4, pp. 323-331, Dec. 2009 <a href="http://dx.doi.org/10.1002/ima.20209">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Multimodal Biometric Authentication Based on the Fusion of Finger Vein and Finger Geometry", Optical Engineering (Letters), vol. 48, issue. 9, 090501, Sep. 2009 <a href="http://dx.doi.org/10.1117/1.3212651">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Restoration of Motion-blurred Iris Image on Mobile Iris Recognition Devices", Optical Engineering, vol. 47, issue. 11, pp. 117202, Nov. 2008 <a href="http://dx.doi.org/10.1117/1.3028280">[link]</a></p>
                <p><I>Young Kyoon Jang, <b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Study on Eyelid Localization Considering Image Focus for Iris Recognition", Pattern Recognition Letters, vol. 29, issue. 11, pp. 1698-1704, Aug. 2008 <a href="http://dx.doi.org/10.1016/j.patrec.2008.05.001">[link]</a></p>
                <p><I>Kang Ryoung Park*, Hyun-Ae Park, <b>Byung Jun Kang</b>, Eui Chul Lee, Dae Sik Jeong, </I> "A Study on Iris Localization and Recognition on Mobile Phone", Eurasip Journal on Advances in Signal Processing, vol. 2008, article ID 281943, 2008 <a href="http://dx.doi.org/10.1155/2008/281943">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "Real-time Image Restoration for Iris Recognition Systems", IEEE Transactions on Systems, Man and Cybernetics - Part B, vol. 37, issue. 6, pp. 1555-1566, Dec. 2007 <a href="http://dx.doi.org/10.1109/TSMCB.2007.907042">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Robust Eyelash Detection Based on Iris Focus Assessment", Pattern Recognition Letters, vol. 28, issue. 13, pp. 1630-1639, Oct. 2007 <a href="http://dx.doi.org/10.1016/j.patrec.2007.04.004">[link]</a></p>
            </div>
        </div>
        <h3>International Conferences</h3>
        <div class="tab-container">
            <div id="ic_tab1" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(2021~current)</span>
                <div class="triangle-button rotated" onclick="toggleContent('ic_content_current', this)"></div>
            </div>       
            <div id="ic_content_current" class="content open">
                <div class="container">
                    <div class="photo">
                        <img src="k_Memseg.jpg" alt="K-means based MemSeg">
                    </div>
                    <div class="profile">
                        <p style="color: #023c71; font-size: min(1.8vw, 2.83vh);"><b>Banknote Fitness Judgment System Using MemSeg Based on K-Means Memory Update</b><p>
                        <p><I>Hui-Jae Bae, Dae-Sik Jung*, <b>Byung Jun Kang*</b></I>
                        <br>International Conference on Electronics, Information, and Communication (ICEIC 2025) <br>Jan. 19~22, 2025 <a href="https://ieeexplore.ieee.org/abstract/document/10879726">[link]</a></p>
                    </div>
                </div>
                <div class="container">
                    <div class="photo">
                        <img src="ReconPatch.jpg" alt="ReconPatch">
                    </div>
                    <div class="profile">
                        <p style="color: #023c71; font-size: min(1.8vw, 2.83vh);"><b>ReConPatch : Contrastive Patch Representation Learning for Industrial Anomaly Detection</b><p>
                        <p><I>Jeeho Hyun, Sangyun Kim, Giyoung Jeon, Seung Hwan Kim, Kyunghoon Bae, <b>Byung Jun Kang*</b></I>
                        <br>IEEE/CVF Winter Conference on Applications of Computer Vision (WACV 2024) <br>Jan. 4~8, 2024 <a href="https://ieeexplore.ieee.org/document/10483692">[link]</a></p>
                    </div>
                </div>
            </div>
            <div id="ic_tab2" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(2005~2020)</span>
                <div class="triangle-button" onclick="toggleContent('ic_content_old', this)"></div>
            </div>
            <div id="ic_content_old" class="content">
                <p><I>Jang-Hee Yoo*, <b>Byung Jun Kang</b>, </I> "A Simply Integrated Dual-Sensor Based Non-Intrusive Iris Image Acquisition System," IEEE Conference on Computer Vision and Pattern Recognition (CVPR) Workshop, Jun. 7~12, 2015 <a href="https://ieeexplore.ieee.org/document/7301304">[link]</a></p>
                <p><I>Jang-Hee Yoo*, <b>Byung Jun Kang</b>, Ki-Young Moon, Jeong-Nyeo Kim, </I> "Automated Power On/Off Control of a Television by Detecting Eye in Face Images," International Conference on Electronics, Information, and Communication (ICEIC 2010), Jun. 30 ~ Jul. 2, 2010 <a href="https://www.dbpia.co.kr/journal/articleDetail?nodeId=NODE01585433">[link]</a></p>
                <p><I>Kwang Yong Shin, Kang Ryoung Park*, <b>Byung Jun Kang</b>, Sung-Joo Park, </I> "Super-Resolution Method based on Multiple Multi-Layer Perceptrons for Iris Recognition", The 4th International Conference on Ubiquitous Information Technologies & Applications (ICUT 2009), Dec. 20~22, 2009 <a href="https://ieeexplore.ieee.org/document/5405701">[link]</a></p>
                <p><I>Hyeon Chang Lee, Kang Ryoung Park*, <b>Byung Jun Kang</b>, Sung-Joo Park, </I> "A New Mobile Multimodal Biometric Device Integrating Finger Vein and Fingerprint," The 4th International Conference on Ubiquitous Information Technologies & Applications (ICUT 2009), Dec. 20~22, 2009. (Best Paper Award) <a href="https://ieeexplore.ieee.org/document/5405686">[link]</a></p>
                <p><I>Kang Ryoung Park*, Dae Sik Jeong, <b>Byung Jun Kang</b>, Eui Chul Lee, </I> "A Study on Iris Feature Watermarking on Face Data", Lecture Notes in Computer Science (ICANNGA’2007),  vol. 4432, pp. 415-423, Apr. 11-14, 2007 <a href="https://link.springer.com/chapter/10.1007/978-3-540-71629-7_47">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Study on Fast Iris Restoration Based on Focus Checking", Lecture Notes in Computer Science (AMDO), Vol. 4069, pp. 19-28, Jul. 11-14, 2006 <a href="https://link.springer.com/chapter/10.1007/11789239_3">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Kang Ryoung Park*, </I> "A Study on Iris Image Restoration", Lecture Notes in Computer Science (AVBPA 2005), Vol. 3546, pp. 31-40, Jul. 2005 <a href="https://link.springer.com/chapter/10.1007/11527923_4">[link]</a></p>
            </div>
        </div>
        <h3>International Patents</h3>
        <div class="tab-container">
            <div id="ip_tab1" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(Granted Patents)</span>
                <div class="triangle-button rotated" onclick="toggleContent('ip_content_grant', this)"></div>
            </div>       
            <div id="ip_content_grant" class="content open">
                <p><I>Dong Kyu Ryu, <b>Byung Jun Kang</b>, Joon Bum CHO, </I> "Device And Method For Detecting Pedestrains", CN104680124B, Dec. 14, 2018 <a href="https://patents.google.com/patent/CN104680124A/en">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Dong Kyu Ryu, </I> "Night pedestrian recognition method based on far-infrared camera head", CN104143098B, Jul. 28, 2017 <a href="https://patents.google.com/patent/CN104143098B/en">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Moon Do Yi, Oh Sung Byun, Soon Wook Chung, </I> "Apparatus and method for certifying driver by recognition face", CN103010159B, Apr. 12, 2017 <a href="https://patents.google.com/patent/CN103010159B/en">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Oh Sung Byun, Moon Do Yi, Soon Wook Chung, </I> "Vehicle driver's certification based on ultrasound wave and condition checkout gear and method thereof", CN103021041B, Aug. 24, 2016 <a href="https://patents.google.com/patent/CN103021041B/en">[link]</a></p>
                <p><I>Dong Kyu Ryu, <b>Byung Jun Kang</b>, Joon Bum CHO, </I> "Apparatus and method for detecting pedestrians", US9349043, May. 24, 2016 <a href="https://patents.google.com/patent/US9349043B2">[link]</a></p>
                <p><I><b>Byung Jun Kang</b>, Dong Kyu Ryu, </I> "Method for detecting pedestrians based on far infrared ray camera at night", US9286512, Mar. 15, 2016 <a href="https://patents.google.com/patent/US9286512B2">[link]</a></p>
                <p><I>Dae-Sung Moon, Ki-Young Moon, Jang-Hee Yoo, Yun-Su Chung, Woo-Yong Choi, So-Hee Park, <b>Byung-Jun Kang</b>, Yong-Jin Lee, </I> "Fingerprint verification method and apparatus with high security", US8699799, Apr. 15, 2014 <a href="https://patents.google.com/patent/US8699799B2">[link]</a></p>
                <p><I>Woo Yong Choi, Dae Sung Moon, Yongjin Lee, Ki Young Moon, Jang-Hee YOO, Yun Su Chung, So-Hee Park, <b>Byung Jun Kang</b>, </I> "Apparatus and method for biometric registration and authentication", US8472680, Jun. 25, 2013 <a href="https://patents.google.com/patent/US8472680B2">[link]</a></p>
            </div>
            <div id="ip_tab2" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(Applied Patents)</span>
                <div class="triangle-button" onclick="toggleContent('ip_content_applied', this)"></div>
            </div>
            <div id="ip_content_applied" class="content">
                <p><I>Jeeho HYUN, Dongsub Shim, Jongseong Jang, Sangyun Kim, <b>Byungjun Kang</b>, Youngsan Koh, Seunghwan Kim, </I> "MEMORY-BASED VISION INSPECTION DEVICE FOR MAINTAINING INSPECTION PERFORMANCE, AND METHOD THEREFOR", US18892502, Sep. 22, 2024 </p>
                <p><I>Sangyun KIM, <b>Byungjun Kang</b>, Youngsan Koh, Jeeho Hyun, Seunghwan Kim, </I> "ARTIFICIAL INTELLIGENCE DEVICE FOR SENSING DEFECTIVE PRODUCTS ON BASIS OF PRODUCT IMAGES AND METHOD THEREFOR", US18892472, Sep. 22, 2024 </p>
                <p><I>Jee Ho HYUN, Sang Yun KIM, Gi Young JEON, Seung Hwan KIM, Kyung Hoon BAE, <b>Byung Jun Kang</b>, </I> "PATCH FEATURE LEARNING METHOD FOR ANOMALY DETECTION, AND SYSTEM THEREFOR", PCT/KR2024/003119, Mar. 11, 2024 </p>
                <p><I><b>Byung Jun Kang</b>, Sang Yun KIM, Jee Ho HYUN, Young San KOH, Run CUI, Seung Hwan KIM, </I> "MACHINE LEARNING-BASED ANOMALY DETECTION DEVICE AND METHOD", PCT/KR2023/019760, Dec. 4, 2023 </p>   
                <p><I>Sangyun KIM, <b>Byungjun Kang</b>, Youngsan Koh, Jeeho Hyun, Seunghwan Kim, </I> "ARTIFICIAL INTELLIGENCE DEVICE FOR DETECTING DEFECTIVE PRODUCT ON BASIS OF PRODUCT IMAGE, AND METHOD THEREFOR", PCT/KR2023/003768, Mar. 22, 2023 </p>
            </div>
        </div>
        <br>
        <h3>Domestic Patents</h3>
        <div class="tab-container">
            <div id="dp_tab1" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(Granted Patents)</span>
                <div class="triangle-button rotated" onclick="toggleContent('dp_content_grant', this)"></div>
            </div>       
            <div id="dp_content_grant" class="content open">
                <p><I><b>강병준</b>, 김성완, </I> "차량 자율 주행 장치 및 차량 자율 주행 방법", KR1025280010000, Apr. 26, 2023 <a href="https://doi.org/10.8080/1020210124323">[link]</a></p>
                <p><I>김승환, <b>강병준</b>, 오웅천, </I> "영상 스트리밍 제어 방법 및 장치", KR1022049940000, Jan. 13, 2021 <a href="https://doi.org/10.8080/1020190038776">[link]</a></p>
                <p><I>유동규, <b>강병준</b>, </I> "야간 주행시 보행자 인식을 위한 운전자 지원 시스템 및 그 동작방법", KR1020784190000, Feb. 11, 2020 <a href="https://doi.org/10.8080/1020130085889">[link]</a></p>
                <p><I><b>강병준</b>, 유동규, </I> "원적외선 카메라 기반 야간 보행자 인식 방법", KR1020211520000, Sep. 5, 2019 <a href="https://doi.org/10.8080/1020130051120">[link]</a></p>
                <p><I>유동규, <b>강병준</b>, </I> "차량용 얼굴인증 장치 및 방법", KR1018597610000, May. 14, 2018 <a href="https://doi.org/10.8080/1020120055467">[link]</a></p>
                <p><I>변오성, 이문도, 정순욱, <b>강병준</b>, </I> "차선 인식 신뢰도 향상 시스템 및 그 방법", KR1018185420000, Jan. 9, 2018 <a href="https://doi.org/10.8080/1020110074212">[link]</a></p>
                <p><I><b>강병준</b>, 이문도, 변오성, 정순욱, </I> "얼굴인식형 운전자 인증 장치 및 방법", KR1018057160000, Nov. 30, 2017 <a href="https://doi.org/10.8080/1020110095441">[link]</a></p>
                <p><I>변오성, 이문도, <b>강병준</b>, </I> "차량의 램프 제어를 위한 주야 판단 방법 및 그 장치", KR1017890740000, Oct. 17, 2017 <a href="https://doi.org/10.8080/1020110132942">[link]</a></p>
                <p><I><b>강병준</b>, 변오성, 이문도, 정순욱, </I> "초음파 기반 차량 운전자 인증 및 상태 감지 장치 및 방법", KR1017676430000, Aug. 7, 2017 <a href="https://doi.org/10.8080/1020110095440">[link]</a></p>
                <p><I><b>강병준</b>, 유장희, 문기영, </I> "홍채 형상의 인식 방법 및 홍채 형상 인식 장치", KR1017637610000, Jul. 26, 2017 <a href="https://doi.org/10.8080/1020100052907">[link]</a></p>
                <p><I>최우용, 문대성, 문기영, 유장희, 정윤수, 박소희, 이한성, <b>강병준</b>, 이용진 김정녀, </I> "안전한 지문 인식 방법", KR1017206560000, Mar. 22, 2017 <a href="https://doi.org/10.8080/1020100052393">[link]</a></p>
                <p><I>최우용, 문대성, 이용진, 문기영, 유장희, 정윤수, 박소희, <b>강병준</b>, </I> "바이오 등록 및 인증 장치와 그 방법", KR1012261510000, Jan. 18, 2013 <a href="https://doi.org/10.8080/1020090075765">[link]</a></p>
                <p><I><b>강병준</b>, 장영균, 이현창, 박강령, </I> "지정맥을 이용한 생체 인식 방법", KR1009547760000, Apr. 19, 2010 <a href="https://doi.org/10.8080/1020080000837">[link]</a></p>
                <p><I>박강령, <b>강병준</b>, </I> "손가락 기하학 정보를 이용한 바이오 인식 방법", KR1009409020000, Jan. 29, 2010 <a href="https://doi.org/10.8080/1020090042006">[link]</a></p>
                <p><I>박강령, 이의철, 신광용, <b>강병준</b>, </I> "피부의 산란에 의해 흐려진 적외선 정맥 영상 복원 방법", KR1009202510000, Sep. 28, 2009 <a href="https://doi.org/10.8080/1020080136915">[link]</a></p>
                <p><I><b>강병준</b>, 장영균, 박강령, 김재희, </I> "홍채 인식 성능 향상을 위한 눈꺼풀 검출과 속눈썹 보간방법", KR1007943610000, Jan. 7, 2008 <a href="https://doi.org/10.8080/1020060119823">[link]</a></p>
            </div>
            <div id="dp_tab2" class="tab" draggable="true" ondragstart="drag(event)">
                <span>(Applied Patents)</span>
                <div class="triangle-button" onclick="toggleContent('dp_content_applied', this)"></div>
            </div>
            <div id="dp_content_applied" class="content">
                <p><I>현지호, 김상윤, 전기영, 김승환, 배경훈, <b>강병준</b>, </I> "어노말리 디텍션을 위한 패치 피처 학습 방법 및 그 시스템", KR1020240032227, Mar. 6, 2024 <a href="https://doi.org/10.8080/1020240032227">[link]</a></p>
                <p><I><b>강병준</b>, 퀴런, 고영산, 현지호, 김상윤, 김승환, </I> "능동 학습 기반의 데이터 분석 장치 및 그 방법", KR1020230000877, Jan. 3, 2023 <a href="https://doi.org/10.8080/1020230000877">[link]</a></p>
                <p><I><b>강병준</b>, 김상윤, 현지호, 고영산, 퀴런, 김승환, </I> "기계 학습 기반 이상 검출 장치 및 방법", KR1020220166645, Dec. 2, 2022 <a href="https://doi.org/10.8080/1020220166645">[link]</a></p>
                <p><I><b>강병준</b>, 김상윤, 고영산, 현지호, 김승환, </I> "제품 이미지를 기반으로 불량 제품을 감지하는 인공 지능 장치 및 그 방법", KR1020220036260, Mar. 23, 2022 <a href="https://doi.org/10.8080/1020220036260">[link]</a></p>
                <p><I>김상윤, <b>강병준</b>, 고영산, 현지호, 김승환, </I> "제품 이미지를 기반으로 불량 제품을 감지하는 인공 지능 장치 및 그 방법", KR1020220036221, Mar. 23, 2022 <a href="https://doi.org/10.8080/1020220036221">[link]</a></p>
                <p><I>현지호, 심동섭, 장종성, 김상윤, <b>강병준</b>, 고영산, 김승환, </I> "검사 성능을 유지하기 위한 메모리 기반 비전 검사 장치 및 그 방법", KR1020220036157, Mar. 23, 2022 <a href="https://doi.org/10.8080/1020220036157">[link]</a></p>
                <p><I>고영산, <b>강병준</b>, 김상윤, 현지호, 김승환, </I> "제품 이미지 패턴 군집화를 기반한 비전검사 인공지능 장치 및 그 방법", KR1020220005796, Jan. 14, 2022 <a href="https://doi.org/10.8080/1020220005796">[link]</a></p>
            </div>
        </div>
    </section>
    <section id="research">
        <h2>Research Topics</h2>
        <div class="container_r">
            <div class="figure">
                <img src="ReConPatch_Results.gif" alt="AD_Results">
            </div>
            <div class="descript">
                <h1>Industrial Image Anomaly Detection</h1>
                <p>산업 제조 분야에서 제품 품질을 유지하는 데 이상 결함 탐지는 매우 중요합니다. 그러나 양산 과정 중에는 불량 샘플이 드물게 생성되어 클래스 불균형 문제가 발생합니다. 
                      이러한 어려움으로 인해 딥러닝 프레임워크 기반 이미지 분류 기술을 효과적으로 활용하기 어렵습니다. 최근 연구에서는 이 문제를 해결하기 위해 다양한 이상 탐지 방법을 제시했습니다. 
                      이상 탐지 정확도를 높이는 방법은 다양하지만, 간결하고 명확하게 정의된 정규 분포를 확보하는 것이 중요합니다. 우리는 MVTec AD 벤치마크 데이터셋에서 성능을 크게 향상시키는 이상 탐지 접근법을 제안한 바 있습니다.
                      이는 정규 특징 벡터의 편차를 효과적으로 완화하는 비지도 대조 학습을 통해 달성됩니다. 이러한 발전에도 불구하고, 이상 탐지는 실제 검사 환경에서 자주 발생하는 분포 변화에 여전히 취약합니다. 
                      이상 탐지 시스템의 신뢰성을 더욱 향상시키기 위한 목표를 달성하기 위해서는 이러한 한계를 극복하기 위한 집중적인 연구가 필요합니다.</p>
                <p>Detecting anomalous defects is crucial for maintaining product quality in the field of industrial manufacturing. However, defective samples are rarely produced during mass production, resulting in an imbalanced class problem. 
                      Such a challenge makes it difficult to utilize image classification techniques based on deep learning frameworks effectively. Recent studies have introduced various anomaly detection methods to address this issue. 
                      There are various methods to enhance the accuracy of anomaly detection, but ensuring a compact and well-defined normal distribution is essential. 
                      We have proposed an anomaly detection approach that significantly improves performance on the MVTec AD benchmark dataset. 
                      This is achieved through unsupervised contrastive learning that effectively mitigates deviations in normal feature vectors. 
                      Despite these advancements, anomaly detection remains vulnerable to distribution shifts that frequently occur in real-world inspection environments. 
                      Addressing these challenges has become a topic of intense research, with the goal of overcoming such limitations and further improving the reliability of anomaly detection systems.</p>
                <p> 관련링크: <a href="https://www.industrynews.co.kr/news/articleView.html?idxno=53505">인더스트리 뉴스 기사</a> / <a href="https://www.sisajournal-e.com/news/articleView.html?idxno=403487">시사저널e 기사</a></p>
            </div>
        </div>
        <div class="container_r">
            <div class="figure">
                <img src="CAM_DEMO.gif" alt="AD_Demo">
            </div>
            <div class="descript">
                <h1>Cameras for Autonomous Driving and ADAS</h1>
                <p>카메라는 자율주행 시스템에서 핵심적인 감각 장치 역할을 하며, 주변 환경에 대한 고해상도 시각 데이터를 제공함으로써 인간의 시각 기관과 유사하게 작동합니다. 
                      이러한 광학 센서는 장애물 감지, 교통 표지판 인식, 차선 이탈 모니터링, 보행자 식별 등 중요한 작업을 수행하는 데 필수적입니다. 
                      카메라 기반 입력 데이터를 LiDAR 및 레이더와 같은 보완적인 센서 장치와 통합하면 복잡한 운영 시나리오에서 강력한 상황 인식 및 의사 결정을 가능하게 합니다. 
                      차선 유지 및 자동 비상 제동 시스템을 포함한 자율주행 기능에 대한 실험적 평가를 수행했습니다. 이 평가는 차량 개체와 취약한 물체를 모두 감지하는 고급 방법론을 적용하여 다양한 시나리오에서 강력한 성능을 보장했습니다. 
                      자율주행 기술은 머신 러닝 알고리즘, 센서 융합 방법론, 그리고 공학 설계의 혁신적인 융합을 보여주는 대표적인 사례입니다.</p>
                <p>Cameras serve as a pivotal sensory modality in autonomous driving systems, functioning analogously to the human visual apparatus by providing high-resolution visual data regarding the surrounding environment. 
                      These optical sensors are indispensable in facilitating critical tasks, including obstacle detection, traffic sign recognition, lane departure monitoring, and pedestrian identification. 
                      The integration of camera-based inputs with complementary sensor modalities, such as LiDAR and radar, allows for robust situational awareness and decision-making in complex operational scenarios. 
                      We conducted experimental evaluations of autonomous driving functions, including lane keeping and autonomous emergency braking systems. The evaluations applied advanced methodologies to detect both vehicle entities and vulnerable objects, ensuring robust performance in a variety of scenarios.
                      Autonomous driving technology exemplifies the innovative convergence of machine learning algorithms, sensor fusion methodologies, and advanced engineering principles.</p>
                <p>관련링크: <a href="https://www.hankyung.com/article/201806018811j">한경 기사</a></p>
            </div>
        </div>
        <div class="container_r">
            <div class="figure">
                <img src="iris_recog.jpg" alt="Iris_Recognition">
            </div>
            <div class="descript">
                <h1>Iris Recognition</h1>
                <p>홍채 인식 기술은 눈의 동공과 공막 사이에 있는 고유한 홍채 패턴을 활용해 개인의 신원을 확인하는 방법입니다. 기존의 홍채 인식 시스템은 카메라와 적외선 조명을 이용해 홍채 이미지를 얻고, 전처리 과정을 통해 눈꺼풀이나 속눈썹을 제외한 홍채 영역을 검출합니다. 이후, 가버 웨이블릿과 DoG 필터 같은 기법을 사용해 홍채 특징을 추출하여 데이터베이스에 등록하거나, 등록된 홍채 정보와 비교해 개인을 인증합니다. 최근에는 딥러닝 기술을 적용해 홍채 영역을 더욱 정확하게 검출하고, 홍채 이미지의 특징을 인코딩하여 인식 정확도를 높이려는 연구가 활발히 진행되고 있습니다. </p>
                <p>Iris recognition technology identifies individuals using the unique iris patterns located between the pupil and the sclera. Traditional iris recognition systems capture images using a camera and infrared lighting, then process the image to detect the iris while excluding elements like eyelids and eyelashes. To extract distinguishing iris features, techniques such as Gabor wavelets and Difference of Gaussian (DoG) filters are applied, creating iris templates that can be stored in a database or compared with registered templates for authentication. Recently, researchers have been integrating deep learning technology to improve the accuracy of iris detection and enhance recognition by encoding iris image features more precisely. This advancement aims to significantly boost the reliability of iris recognition systems.</p>
                <p>관련링크: <a href="https://ieeexplore.ieee.org/document/7301304">CVPR2015 Workshop</a></p>
            </div>
        </div>
    </section>
    <footer>
        <p>&copy; 2025 B.J. Kang. All rights reserved.</p>
    </footer>

    <script>
        function allowDrop(event) {
            event.preventDefault();
        }

        function drag(event) {
            event.dataTransfer.setData("text", event.target.id);
        }

        function drop(event) {
            event.preventDefault();
            var tabId = event.dataTransfer.getData("text");
            var contentId = tabId === "tab1" ? "content1" : "content2";

            document.querySelectorAll('.content').forEach(content => content.classList.remove('open'));
            document.getElementById(contentId).classList.add('open');
        }

        function toggleContent(contentId, button) {
            var content = document.getElementById(contentId);
            content.classList.toggle('open');
            button.classList.toggle('rotated');
        }
    </script>
</body>
</html>
